model:
  num_classes: 1
  num_frames: 8 # number of frames to process
  embed_dims: 256
  num_heads: 8
  ff_dim: 2048
  num_transformer_layers: 6 # number of transformer layers
  dropout_rate: 0.4 #spatial dropout rate
  use_spatial_attention: true # whether to use spatial attention

data:
  data_dir: "/kaggle/input/celeb-df/dataset"
  batch_size: 16
  num_frames: 8
  frame_size: [224, 224]
  normalize: true

training:
  epochs: 80
  learning_rate: 0.001
  fine-tune_lr: 0.00001
  freeze_epochs: 10
  optimizer: "adam"
  loss: "binary_crossentropy"
  metrics: ["accuracy", "precision", "recall", "roc_auc", "pr_auc"]
  checkpoint_dir: "./checkpoints"
  log_dir: "./logs"
