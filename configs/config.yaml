model:
  num_classes: 1
  num_frames: 8 # number of frames to process
  embed_dims: 512
  num_heads: 8
  ff_dim: 1024
  num_transformer_layers: 6 # number of transformer layers
  dropout_rate: 0.2 #spatial dropout rate
  use_spatial_attention: true

data:
  data_dir: "/kaggle/input/celeb-df/dataset"
  batch_size: 16
  num_frames: 8
  frame_size: [224, 224]
  normalize: true

training:
  epochs: 50
  learning_rate: 0.001
  fine-tune_lr: 0.00001
  freeze_epochs: 40
  optimizer: "adam"
  loss: "binary_crossentropy"
  metrics: ["accuracy"]
  checkpoint_dir: "./checkpoints"
  log_dir: "./logs"
